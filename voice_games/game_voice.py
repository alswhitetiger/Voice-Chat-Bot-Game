import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv
from playsound import playsound

load_dotenv()
client = OpenAI()
recognizer = sr.Recognizer()

conversation_history = [
    {
        "role": "system",
        "content": "ë‹¹ì‹ ì€ í˜¸ê·¸ì™€íŠ¸ì˜ êµì¥ ì•Œë²„ìŠ¤ ë¤ë¸”ë„ì–´ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì‹ ì…ìƒì…ë‹ˆë‹¤. ì£¼ë³€ ìƒí™©ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•˜ê³ , í•­ìƒ ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒì— ë¬´ì—‡ì„ í•  ê²ƒì¸ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ëŒ€ë‹µì€ ê°„ê²°í•˜ê²Œ 1~3 ë¬¸ì¥ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”."
    }
]

def listen_and_recognize():
    with sr.Microphone() as source:
        print("\nğŸ§ í–‰ë™ì„ ë§ì”€í•˜ì„¸ìš”...")
        recognizer.adjust_for_ambient_noise(source)
        audio = recognizer.listen(source)
        try:
            return recognizer.recognize_google(audio, language='ko-KR')
        except (sr.UnknownValueError, sr.RequestError):
            return "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

def generate_and_speak(text):
    print(f"\nğŸ¤ ë¤ë¸”ë„ì–´ êµìˆ˜:\n{text}\n")
    with client.audio.speech.with_streaming_response.create(
        model='tts-1', voice='nova', input=text
    ) as response:
        response.stream_to_file("response.mp3")
    playsound("response.mp3")

initial_message = "ì˜¤ëœë§Œì´ë‹¤, ìƒˆë¡œìš´ ë§ˆë²•ì‚¬ì—¬. ì´ê³³ í˜¸ê·¸ì™€íŠ¸ì— ì˜¨ ê²ƒì„ ì§„ì‹¬ìœ¼ë¡œ í™˜ì˜í•œë‹¤. ì´ì œ ë„ˆì˜ ëª¨í—˜ì´ ì‹œì‘ë  ê²ƒì´ë‹¤. ì²« ë²ˆì§¸ë¡œ ì–´ë–¤ ìˆ˜ì—…ì— ì°¸ì—¬í•˜ê³  ì‹¶ìœ¼ëƒ?"
conversation_history.append({"role": "assistant", "content": initial_message})
generate_and_speak(initial_message)

while True:
    action = listen_and_recognize()
    print(f"ğŸ‘¤ ë‚˜:\n{action}\n")

    if "ì¢…ë£Œ" in action or "ê·¸ë§Œ" in action:
        generate_and_speak("ë‹¤ìŒ ëª¨í—˜ì—ì„œ ë‹¤ì‹œ ë§Œë‚˜ë„ë¡ í•˜ì§€.")
        break
    
    conversation_history.append({"role": "user", "content": action})

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=conversation_history,
        temperature=0.8,
    )
    ai_response = response.choices[0].message.content
    
    conversation_history.append({"role": "assistant", "content": ai_response})
    generate_and_speak(ai_response)