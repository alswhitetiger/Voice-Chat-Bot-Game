import streamlit as st
import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv
from streamlit_mic_recorder import mic_recorder
import io
from pydub import AudioSegment

# --- ì´ˆê¸° ì„¤ì • ---
load_dotenv()
st.set_page_config(page_title="í˜¸ê·¸ì™€íŠ¸ ë§ˆë²• ëª¨í—˜", layout="centered")
client = OpenAI()
recognizer = sr.Recognizer()

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ í˜¸ê·¸ì™€íŠ¸ì˜ êµì¥ ì•Œë²„ìŠ¤ ë¤ë¸”ë„ì–´ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì‹ ì…ìƒì…ë‹ˆë‹¤. ì£¼ë³€ ìƒí™©ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•˜ê³ , í•­ìƒ ì‚¬ìš©ìì—ê²Œ ë‹¤ìŒì— ë¬´ì—‡ì„ í•  ê²ƒì¸ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ëŒ€ë‹µì€ ê°„ê²°í•˜ê²Œ 1~3 ë¬¸ì¥ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”."},
        {"role": "assistant", "content": "ì˜¤ëœë§Œì´ë‹¤, ìƒˆë¡œìš´ ë§ˆë²•ì‚¬ì—¬. ì´ê³³ í˜¸ê·¸ì™€íŠ¸ì— ì˜¨ ê²ƒì„ ì§„ì‹¬ìœ¼ë¡œ í™˜ì˜í•œë‹¤. ì´ì œ ë„ˆì˜ ëª¨í—˜ì´ ì‹œì‘ë  ê²ƒì´ë‹¤. ì²« ë²ˆì§¸ë¡œ ì–´ë–¤ ìˆ˜ì—…ì— ì°¸ì—¬í•˜ê³  ì‹¶ìœ¼ëƒ?"}
    ]
if "last_audio_id" not in st.session_state:
    st.session_state.last_audio_id = None

# --- ë°°ê²½ ë° UI ìŠ¤íƒ€ì¼ ---
HOGWARTS_BACKGROUND_URL = "https://search.pstatic.net/sunny/?src=https%3A%2F%2Fwallpapers.com%2Fimages%2Fhd%2Fthe-magical-world-of-hogwarts-castle-at-twilight-qddsrb40uub1v5jo.jpg&type=sc960_832"
st.markdown(f"""
<style>
.stApp {{
    background-image: url("{HOGWARTS_BACKGROUND_URL}");
    background-size: cover; background-position: center; background-attachment: fixed;
}}
.stChatMessage {{
    background-color: rgba(255, 255, 255, 0.7); border-radius: 10px;
}}
h1 {{
    color: #FFFFFF; text-shadow: 2px 2px 4px #000000;
}}
</style>
""", unsafe_allow_html=True)
st.title("ğŸ§™â€â™‚ï¸ í˜¸ê·¸ì™€íŠ¸ ë§ˆë²• ëª¨í—˜")

# --- ì‚¬ì´ë“œë°” ë©”ë‰´ ---
with st.sidebar:
    st.header("ê²Œì„ ë©”ë‰´")
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

    with st.expander("ì „ì²´ ëŒ€í™” ë‚´ìš© ë³´ê¸°"):
        st.write(st.session_state.get("messages", "ì•„ì§ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤."))

# --- í•µì‹¬ í•¨ìˆ˜ ---
def text_to_speech(text):
    response = client.audio.speech.create(model='tts-1', voice='nova', input=text)
    return response.read()

def handle_response(user_text):
    st.session_state.messages.append({"role": "user", "content": user_text})
    
    response = client.chat.completions.create(model="gpt-4o-mini", messages=st.session_state.messages)
    ai_response = response.choices[0].message.content
    st.session_state.messages.append({"role": "assistant", "content": ai_response})
    
    st.session_state.audio_to_play = text_to_speech(ai_response)

# --- ì±„íŒ… UI í‘œì‹œ ---
for msg in st.session_state.messages:
    if msg["role"] != "system":
        st.chat_message(msg["role"]).write(msg["content"])

# --- ìŒì„± ë° í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬ ---
st.sidebar.divider()
st.sidebar.subheader("ë§ˆë²• ì£¼ë¬¸ ì™¸ìš°ê¸° (ìŒì„±)")
audio_info = mic_recorder(start_prompt="ğŸ¤ ë…¹ìŒ ì‹œì‘", stop_prompt="ğŸ›‘ ë…¹ìŒ ì¤‘ì§€", key='recorder')

if audio_info and audio_info['id'] != st.session_state.last_audio_id:
    st.session_state.last_audio_id = audio_info['id']
    audio_bytes = audio_info['bytes']
    
    try:
        sound = AudioSegment.from_file(io.BytesIO(audio_bytes))
        wav_io = io.BytesIO()
        sound.export(wav_io, format="wav")
        wav_io.seek(0)

        with sr.AudioFile(wav_io) as source:
            audio_data = recognizer.record(source)
        user_text = recognizer.recognize_google(audio_data, language='ko-KR')
        
        handle_response(user_text)
        st.rerun()
        
    except (sr.UnknownValueError, sr.RequestError):
        st.warning("ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    except Exception:
        st.error("ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

if user_text_input := st.chat_input("ë§ˆë²• ì£¼ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    handle_response(user_text_input)
    st.rerun()

# --- ì˜¤ë””ì˜¤ ì¬ìƒ ë° ê²Œì„ ì‹œì‘ ìŒì„± ---
if "audio_to_play" in st.session_state:
    st.audio(st.session_state.pop("audio_to_play"), autoplay=True)

if "start_audio_played" not in st.session_state:
    initial_message = st.session_state.messages[1]["content"]
    st.session_state.audio_to_play = text_to_speech(initial_message)
    st.session_state.start_audio_played = True
    st.rerun()